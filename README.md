# Comparative Analysis of RNN Architectures for Sentiment Classification

This repository contains the code for a master's-level project in Data Science, implementing a systematic comparison of **RNN**, **LSTM**, and **Bidirectional LSTM** models for sentiment classification.  
The project runs **36 experiments** to analyze the impact of architecture, optimizer, sequence length, and gradient clipping on model performance.

---

## Project Structure

```
SentimentRNN/
│
├── data/
│   └── IMDB Dataset.csv           # (Must be downloaded manually)
│
├── results/
│   ├── metrics.csv                # (Generated by run_experiments.py)
│   └── plots/                     # (Generated by analysis & loss plot scripts)
│       ├── f1_vs_seq_length.png
│       ├── optimizer_comparison.png
│       ├── clipping_effect.png
│       ├── loss_vs_epochs_TRAIN.png
│       └── loss_vs_epochs_VALIDATION.png
│
├── src/
│   ├── __init__.py                # (Makes 'src' a Python package)
│   ├── preprocess.py              # (Data loading and preprocessing pipeline)
│   ├── models.py                  # (Defines SentimentRNN, LSTM, BiLSTM models)
│   ├── train.py                   # (Runs a single training & evaluation experiment)
│   ├── utils.py                   # (Seeding function for reproducibility)
│   └── generate_loss_plot.py      # (Generates loss curves for best/worst models)
│
├── run_experiments.py             # (Runner script to automate all 36 experiments)
├── requirements.txt               # (Python dependencies)
├── report.pdf                     # (The final written report - not included here)
└── README.md                      # (This file)
```

---

## Setup Instructions

### 1. Environment

This project was built using **Python 3.10+**.

### 2. Dependencies

Install all required libraries using `pip`:

```bash
pip install -r requirements.txt
```

### 3. Data

1. Download the **IMDb Movie Review Dataset** from Kaggle:  
   <https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews>

2. Place the downloaded `IMDB Dataset.csv` file inside the `data/` folder.

---

## How to Run

All commands should be run from the root directory (`SentimentRNN/`).  
This project was developed in a **Google Colab environment** using a **T4 GPU**.

### 1. Run a Single Experiment

You can run a single experiment with custom parameters using `src/train.py`.  
The `-m` flag is required to handle the package imports correctly.

**Example: Run a single baseline test**

```bash
python -m src.train --model_type 'LSTM' --optimizer 'Adam' --seq_len 50
```

---

### 2. Run the Full 36-Experiment Suite

To reproduce the main results, run the `run_experiments.py` script. This will:

1. Clear any old data in `results/metrics.csv`.
2. Run all 36 experiments.
3. Save the final metrics for each run to `results/metrics.csv`.
4. Print a sorted summary table to the console.

This script took approximately **49 minutes** to complete on a **T4 GPU**.

```bash
python run_experiments.py
```

---

### 3. Generate Analysis Plots

The `Sentiment_Analysis_Report.md` file (or a Colab notebook) contains the `pandas` and `seaborn` code  
to analyze the `results/metrics.csv` file and generate the primary plots.

---

### 4. Generate Loss Curves

To generate the final "Loss vs. Epochs" plots for the best and worst models, run:

```bash
python -m src.generate_loss_plot
```

This will save:

- `loss_vs_epochs_TRAIN.png`
- `loss_vs_epochs_VALIDATION.png`

to the `results/plots/` folder.

---

## Results

- **Raw Data:** All experimental results are aggregated in `results/metrics.csv`.
- **Plots:** All plots for the final report are saved in `results/plots/`.
- **Final Report:** The complete analysis and discussion are available in  
  `Sentiment_Analysis_Report.md` (or `report.pdf`).

---
